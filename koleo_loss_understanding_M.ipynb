{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e514ccc6-5f08-4a06-88a9-ad817fdb6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# This source code is licensed under the Apache License, Version 2.0\n",
    "# found in the LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import torch.distributed as dist\n",
    "\n",
    "\n",
    "logger = logging.getLogger(\"dinov2\")\n",
    "\n",
    "\n",
    "class KoLeoLoss(nn.Module):\n",
    "    \"\"\"Kozachenko-Leonenko entropic loss regularizer from Sablayrolles et al. - 2018 - Spreading vectors for similarity search\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pdist = nn.PairwiseDistance(2, eps=1e-8)\n",
    "\n",
    "    def pairwise_NNs_inner(self, x):\n",
    "        \"\"\"\n",
    "        Pairwise nearest neighbors for L2-normalized vectors.\n",
    "        Uses Torch rather than Faiss to remain on GPU.\n",
    "        \"\"\"\n",
    "        # parwise dot products (= inverse distance)\n",
    "        dots = torch.mm(x, x.t())\n",
    "        n = x.shape[0]\n",
    "        dots.view(-1)[:: (n + 1)].fill_(-1)  # Trick to fill diagonal with -1\n",
    "        # max inner prod -> min distance\n",
    "        _, I = torch.max(dots, dim=1)  # noqa: E741\n",
    "        return I\n",
    "\n",
    "    def forward(self, student_output, eps=1e-8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            student_output (BxD): backbone output of student\n",
    "        \"\"\"\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            student_output = F.normalize(student_output, eps=eps, p=2, dim=-1)\n",
    "            print(student_output)\n",
    "            I = self.pairwise_NNs_inner(student_output)  # noqa: E741\n",
    "            distances = self.pdist(student_output, student_output[I])  # BxD, BxD -> B\n",
    "            loss = -torch.log(distances + eps).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0d2a3-d1fd-41db-8fb4-0f4db793e2d2",
   "metadata": {},
   "source": [
    "The KoLeoLoss class implements a custom loss function based on the Kozachenko-Leonenko entropic loss regularizer, as described by Sablayrolles et al. in their 2018 paper **\"Spreading vectors for similarity search\"**. \n",
    "\n",
    "This loss function is designed to encourage the spread of vectors for similarity search tasks.\n",
    "\n",
    "This spreading of vectors can be beneficial for tasks such as similarity search, where distinct and well-separated representations are desirable for efficient and accurate retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f93bc89-ccd6-49d0-b4be-e48b2b0498c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2874, 0.3161, 0.3448, 0.3736, 0.4023, 0.4310, 0.4598],\n",
       "        [0.2499, 0.5498, 0.2999, 0.3749, 0.3499, 0.3499, 0.3999],\n",
       "        [0.3420, 0.3876, 0.2736, 0.2964, 0.3192, 0.3420, 0.5927],\n",
       "        [0.2902, 0.3192, 0.3483, 0.3773, 0.3773, 0.4353, 0.4673],\n",
       "        [0.3440, 0.3873, 0.2734, 0.2961, 0.3189, 0.3417, 0.5923]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 1e-8\n",
    "student_output = torch.tensor([[1, 1.1, 1.2, 1.3 ,1.4 ,1.5, 1.6],\n",
    "                               [1, 2.2, 1.2, 1.5 ,1.4 ,1.4, 1.6],\n",
    "                               [1.5, 1.7, 1.2, 1.3 ,1.4 ,1.5, 2.6],\n",
    "                               [1, 1.1, 1.2, 1.3 ,1.3 ,1.5, 1.61],\n",
    "                               [1.51, 1.7, 1.2, 1.3 ,1.4 ,1.5, 2.6]])\n",
    "student_output = F.normalize(student_output, eps=1e-8, p=2, dim=-1)\n",
    "student_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "305fdf30-d71f-4a38-bfd3-7dfc45cda214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.9645, 0.9742, 0.9996, 0.9741],\n",
      "        [0.9645, 1.0000, 0.9601, 0.9651, 0.9599],\n",
      "        [0.9742, 0.9601, 1.0000, 0.9763, 1.0000],\n",
      "        [0.9996, 0.9651, 0.9763, 1.0000, 0.9762],\n",
      "        [0.9741, 0.9599, 1.0000, 0.9762, 1.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000,  0.9645,  0.9742,  0.9996,  0.9741],\n",
       "        [ 0.9645, -1.0000,  0.9601,  0.9651,  0.9599],\n",
       "        [ 0.9742,  0.9601, -1.0000,  0.9763,  1.0000],\n",
       "        [ 0.9996,  0.9651,  0.9763, -1.0000,  0.9762],\n",
       "        [ 0.9741,  0.9599,  1.0000,  0.9762, -1.0000]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = student_output        #5x7\n",
    "dots = torch.mm(x, x.t()) #5x5\n",
    "n = x.shape[0]            #5\n",
    "print(dots)\n",
    "dots.view(-1)[:: (n + 1)].fill_(-1) # wow it was applied in 2d without reshaping saved!\n",
    "dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24a85cfa-6ee1-464a-bd91-66798caef07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 4, 0, 2])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, I = torch.max(dots, dim=1)\n",
    "# notice the 0th batch and 3rd are almost the same in student_output, 2nd and 4th\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a15f3ca1-fde9-404e-bbea-298901b047b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2874, 0.3161, 0.3448, 0.3736, 0.4023, 0.4310, 0.4598],\n",
      "        [0.2499, 0.5498, 0.2999, 0.3749, 0.3499, 0.3499, 0.3999],\n",
      "        [0.3420, 0.3876, 0.2736, 0.2964, 0.3192, 0.3420, 0.5927],\n",
      "        [0.2902, 0.3192, 0.3483, 0.3773, 0.3773, 0.4353, 0.4673],\n",
      "        [0.3440, 0.3873, 0.2734, 0.2961, 0.3189, 0.3417, 0.5923]])\n",
      "tensor([[0.2902, 0.3192, 0.3483, 0.3773, 0.3773, 0.4353, 0.4673],\n",
      "        [0.2902, 0.3192, 0.3483, 0.3773, 0.3773, 0.4353, 0.4673],\n",
      "        [0.3440, 0.3873, 0.2734, 0.2961, 0.3189, 0.3417, 0.5923],\n",
      "        [0.2874, 0.3161, 0.3448, 0.3736, 0.4023, 0.4310, 0.4598],\n",
      "        [0.3420, 0.3876, 0.2736, 0.2964, 0.3192, 0.3420, 0.5927]])\n"
     ]
    }
   ],
   "source": [
    "print(student_output)\n",
    "print(student_output[I])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4ecf5-d855-4fad-9e7f-c2c447f09ea0",
   "metadata": {},
   "source": [
    " the distance between a bactch rep with its nearest representation, make them smaller!!!!\n",
    " \n",
    " NOOOO, make them bigger. \n",
    " \n",
    "For d = 0.01: ............. Loss: -log(0.01) â‰ˆ 4.605\n",
    "\n",
    "For d = 1: ............. Loss: -log(1) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7bd51dc-be68-40f3-978f-d5a31c04e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0273, 0.2641, 0.0021, 0.0273, 0.0021])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdist = nn.PairwiseDistance(2, eps=eps)\n",
    "distances = pdist(student_output, student_output[I])\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9836fb-680b-4c8a-8cc4-c53bd85702e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d13100-fb77-49c3-9475-062f3137c778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7281d909-71f9-4d4c-85f5-5f590e55309a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1657)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -torch.log(distances + eps).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc1daa64-9d80-43c9-98e4-cac2f4098f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairwiseDistance()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56167285-e30f-414b-8135-a643f169d042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
