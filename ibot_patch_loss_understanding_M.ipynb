{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b087a7a6-81dc-4153-88fb-f0b36e0a8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# This source code is licensed under the Apache License, Version 2.0\n",
    "# found in the LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import logging\n",
    "logger = logging.getLogger(\"dinov2\")\n",
    "\n",
    "try:\n",
    "    from xformers.ops import cross_entropy\n",
    "\n",
    "    def lossfunc(t, s, temp):\n",
    "        s = s.float()\n",
    "        t = t.float()\n",
    "        if s.ndim == 2:\n",
    "            return -cross_entropy(s.unsqueeze(0), t.unsqueeze(0), temp, bw_inplace=True).squeeze(0)\n",
    "        elif s.ndim == 3:\n",
    "            return -cross_entropy(s, t, temp, bw_inplace=True)\n",
    "\n",
    "except ImportError:\n",
    "\n",
    "    def lossfunc(t, s, temp):\n",
    "        return torch.sum(t * F.log_softmax(s / temp, dim=-1), dim=-1)\n",
    "    #dim=-1: Specifies that the softmax operation should be applied along the \n",
    "    #last dimension of the tensor. This is typically the feature dimension in the context\n",
    "    #of a batch of data.\n",
    "\n",
    "\n",
    "class iBOTPatchLoss(nn.Module):\n",
    "    def __init__(self, patch_out_dim, student_temp=0.1, center_momentum=0.9):\n",
    "        super().__init__()\n",
    "        self.student_temp = student_temp\n",
    "        self.center_momentum = center_momentum\n",
    "        self.register_buffer(\"center\", torch.zeros(1, 1, patch_out_dim))\n",
    "        self.updated = True\n",
    "        self.reduce_handle = None\n",
    "        self.len_teacher_patch_tokens = None\n",
    "        self.async_batch_center = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def softmax_center_teacher(self, teacher_patch_tokens, teacher_temp):\n",
    "        self.apply_center_update()\n",
    "        # teacher centering and sharpening\n",
    "        #\n",
    "        # WARNING:\n",
    "        #   as self.center is a float32, everything gets casted to float32 afterwards\n",
    "        #\n",
    "        # teacher_patch_tokens = teacher_patch_tokens.float()\n",
    "        # return F.softmax((teacher_patch_tokens.sub_(self.center.to(teacher_patch_tokens.dtype))).mul_(1 / teacher_temp), dim=-1)\n",
    "\n",
    "        return F.softmax((teacher_patch_tokens - self.center) / teacher_temp, dim=-1)\n",
    "\n",
    "        # this is experimental, keep everything in float16 and let's see what happens:\n",
    "        # return F.softmax((teacher_patch_tokens.sub_(self.center)) / teacher_temp, dim=-1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sinkhorn_knopp_teacher(self, teacher_output, teacher_temp, n_masked_patches_tensor, n_iterations=3):\n",
    "        teacher_output = teacher_output.float()\n",
    "        # world_size = dist.get_world_size() if dist.is_initialized() else 1\n",
    "        Q = torch.exp(teacher_output / teacher_temp).t()  # Q is K-by-B for consistency with notations from our paper\n",
    "        # B = Q.shape[1] * world_size # number of samples to assign\n",
    "        B = n_masked_patches_tensor\n",
    "        dist.all_reduce(B)\n",
    "        K = Q.shape[0]  # how many prototypes\n",
    "\n",
    "        # make the matrix sums to 1\n",
    "        sum_Q = torch.sum(Q)\n",
    "        if dist.is_initialized():\n",
    "            dist.all_reduce(sum_Q)\n",
    "        Q /= sum_Q\n",
    "\n",
    "        for it in range(n_iterations):\n",
    "            # normalize each row: total weight per prototype must be 1/K\n",
    "            sum_of_rows = torch.sum(Q, dim=1, keepdim=True)\n",
    "            if dist.is_initialized():\n",
    "                dist.all_reduce(sum_of_rows)\n",
    "            Q /= sum_of_rows\n",
    "            Q /= K\n",
    "\n",
    "            # normalize each column: total weight per sample must be 1/B\n",
    "            Q /= torch.sum(Q, dim=0, keepdim=True)\n",
    "            Q /= B\n",
    "\n",
    "        Q *= B  # the columns must sum to 1 so that Q is an assignment\n",
    "        return Q.t()\n",
    "\n",
    "    def forward(self, student_patch_tokens, teacher_patch_tokens, student_masks_flat):\n",
    "        \"\"\"\n",
    "        Cross-entropy between softmax outputs of the teacher and student networks.\n",
    "        student_patch_tokens: (B, N, D) tensor\n",
    "        teacher_patch_tokens: (B, N, D) tensor\n",
    "        student_masks_flat: (B, N) tensor\n",
    "        \"\"\"\n",
    "        t = teacher_patch_tokens\n",
    "        s = student_patch_tokens\n",
    "        loss = torch.sum(t * F.log_softmax(s / self.student_temp, dim=-1), dim=-1)\n",
    "        loss = torch.sum(loss * student_masks_flat.float(), dim=-1) / student_masks_flat.sum(dim=-1).clamp(min=1.0)\n",
    "        return -loss.mean()\n",
    "\n",
    "    def forward_masked(\n",
    "        self,\n",
    "        student_patch_tokens_masked,\n",
    "        teacher_patch_tokens_masked,\n",
    "        student_masks_flat,\n",
    "        n_masked_patches=None,\n",
    "        masks_weight=None,\n",
    "    ):\n",
    "        t = teacher_patch_tokens_masked\n",
    "        s = student_patch_tokens_masked\n",
    "        # loss = torch.sum(t * F.log_softmax(s / self.student_temp, dim=-1), dim=-1)\n",
    "        loss = lossfunc(t, s, self.student_temp)\n",
    "        if masks_weight is None:\n",
    "            masks_weight = (\n",
    "                (1 / student_masks_flat.sum(-1).clamp(min=1.0))\n",
    "                .unsqueeze(-1)\n",
    "                .expand_as(student_masks_flat)[student_masks_flat]\n",
    "            )\n",
    "        if n_masked_patches is not None:\n",
    "            loss = loss[:n_masked_patches]\n",
    "        loss = loss * masks_weight\n",
    "        return -loss.sum() / student_masks_flat.shape[0]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_center(self, teacher_patch_tokens):\n",
    "        self.reduce_center_update(teacher_patch_tokens)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reduce_center_update(self, teacher_patch_tokens):\n",
    "        self.updated = False\n",
    "        self.len_teacher_patch_tokens = len(teacher_patch_tokens)\n",
    "        self.async_batch_center = torch.sum(teacher_patch_tokens.mean(1), dim=0, keepdim=True)\n",
    "        if dist.is_initialized():\n",
    "            self.reduce_handle = dist.all_reduce(self.async_batch_center, async_op=True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def apply_center_update(self):\n",
    "        if self.updated is False:\n",
    "            world_size = dist.get_world_size() if dist.is_initialized() else 1\n",
    "\n",
    "            if self.reduce_handle is not None:\n",
    "                self.reduce_handle.wait()\n",
    "            _t = self.async_batch_center / (self.len_teacher_patch_tokens * world_size)\n",
    "\n",
    "            self.center = self.center * self.center_momentum + _t * (1 - self.center_momentum)\n",
    "\n",
    "            self.updated = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e0642226-e2e3-4f00-b138-a0f3b1adf143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7183916568756104\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "batch_size = 1\n",
    "num_patches = 4\n",
    "patch_dim = 3\n",
    "\n",
    "student_temp=0.1\n",
    "center_momentum=0.9\n",
    "\n",
    "# Dummy data\n",
    "student_patch_tokens = torch.randn(batch_size, num_patches, patch_dim)\n",
    "teacher_patch_tokens = torch.randn(batch_size, num_patches, patch_dim)\n",
    "student_masks_flat = torch.randint(0, 2, (batch_size, num_patches)).float()  #tensor([[1., 0., 1., 0.]])\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = iBOTPatchLoss(patch_out_dim=patch_dim)\n",
    "\n",
    "# Compute the loss\n",
    "loss = loss_fn(student_patch_tokens, teacher_patch_tokens, student_masks_flat)\n",
    "print(f'Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b287ddb0-a10f-4fdd-9528-31ef54d4a228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_masks_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a3206013-e3d3-4eee-aa68-d49ed7dc9212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, student_patch_tokens, teacher_patch_tokens, student_masks_flat):\n",
    "    t = teacher_patch_tokens   \n",
    "    s = student_patch_tokens\n",
    "    loss = torch.sum(t * F.log_softmax(s / self.student_temp, dim=-1), dim=-1)\n",
    "    loss = torch.sum(loss * student_masks_flat.float(), dim=-1) / student_masks_flat.sum(dim=-1).clamp(min=1.0)\n",
    "    return -loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c22b0f03-d545-4d31-957c-44be5fd1ebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9904, -0.7244, -1.0313],\n",
       "         [-0.5965, -1.2006, -0.5768],\n",
       "         [ 0.8252,  1.3768,  1.7738],\n",
       "         [ 0.8361,  0.5736, -0.0891]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = student_patch_tokens\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4712c972-91f2-4edc-80dc-a29ce9a2e3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.2615e-02, 8.9580e-01, 4.1589e-02],\n",
       "         [4.5050e-01, 1.0712e-03, 5.4842e-01],\n",
       "         [7.4442e-05, 1.8525e-02, 9.8140e-01],\n",
       "         [9.3232e-01, 6.7590e-02, 8.9417e-05]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(s / 0.1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f2486e56-88b0-49f6-a8c8-640ab0c68671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.7708, -0.1100, -3.1799],\n",
       "         [-0.7974, -6.8390, -0.6007],\n",
       "         [-9.5055, -3.9887, -0.0188],\n",
       "         [-0.0701, -2.6943, -9.3222]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(s / 0.1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7df1eb79-6930-4ac0-af67-39e90c3a2228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3983, 0.1297, 0.1776, 0.2745, 0.0199],\n",
      "        [0.1030, 0.2527, 0.2393, 0.2110, 0.1941],\n",
      "        [0.0215, 0.2209, 0.3148, 0.0742, 0.3685],\n",
      "        [0.2831, 0.0533, 0.0480, 0.2742, 0.3414],\n",
      "        [0.1902, 0.3465, 0.2231, 0.1637, 0.0765]])\n"
     ]
    }
   ],
   "source": [
    "# From chatGPT (does not work when it is not square!)\n",
    "#Row Normalization: Each row is normalized to sum to 1/K.\n",
    "#Column Normalization: Each column is normalized to sum to 1/B in the for loop.\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sinkhorn_knopp(teacher_output, num_iterations=3):\n",
    "    \"\"\"\n",
    "    Applies the Sinkhorn-Knopp algorithm to normalize the teacher output.\n",
    "    \n",
    "    Args:\n",
    "        teacher_output (torch.Tensor): The output logits from the teacher network, shape (B, K) where B is the batch size and K is the number of prototypes.\n",
    "        num_iterations (int): Number of iterations for the Sinkhorn-Knopp algorithm.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The normalized output, shape (B, K).\n",
    "    \"\"\"\n",
    "    Q = torch.exp(teacher_output).t()  # Transpose to have K x B\n",
    "    B, K = Q.shape[1], Q.shape[0]\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # Normalize rows\n",
    "        Q /= torch.sum(Q, dim=1, keepdim=True)\n",
    "        Q /= K\n",
    "\n",
    "        # Normalize columns\n",
    "        Q /= torch.sum(Q, dim=0, keepdim=True)\n",
    "        Q /= B\n",
    "\n",
    "    Q *= B  # Rescale the columns to sum to 1\n",
    "    return Q.t()  # Transpose back to B x K\n",
    "\n",
    "# Example usage\n",
    "batch_size = 5\n",
    "num_prototypes = 5\n",
    "\n",
    "# Simulated teacher output logits\n",
    "teacher_output = torch.randn(batch_size, num_prototypes)\n",
    "# teacher_output = torch.tensor([[ 10,  2,  3,  4,  5],\n",
    "#         [ 60.,  7,  8,  9, 10],\n",
    "#         [11, 12, 13, 14, 15],\n",
    "#         [16, 17, 18, 19, 20],\n",
    "#         [21, 22, 23, 24, 25]])\n",
    "\n",
    "# Apply Sinkhorn-Knopp normalization\n",
    "normalized_output = sinkhorn_knopp(teacher_output)\n",
    "print(normalized_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c933ad15-5c5a-41cd-a17e-0fd28444c3f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2317, -0.1360,  0.9248,  0.7052, -1.3081],\n",
       "        [-0.5308,  0.1209,  0.8131,  0.0324,  0.5588],\n",
       "        [-2.0928, -0.0104,  1.0902, -1.0095,  1.2026],\n",
       "        [ 1.1024, -0.8132, -0.1703,  0.9166,  1.7455],\n",
       "        [-0.6171, -0.2631,  0.0432, -0.9210, -1.0722]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "619af3a1-096f-4928-835d-b25da6c925b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9065, -1.1017,  2.7009, -0.2763,  1.1267])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(teacher_output,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1f2df5bd-fbb6-4d83-869d-44e349d53334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4177,  0.9944, -0.8200,  2.7811, -2.8302])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(teacher_output,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ed34e288-954d-472c-801c-04b0c5669d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9961, 1.0031, 1.0028, 0.9977, 1.0003])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(normalized_output,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5bbf2ef7-679e-4c6e-b578-21c054abde8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(normalized_output,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8ac0c721-135d-4484-8d45-82359cd9e3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [11, 12, 13, 14, 15],\n",
       "        [16, 17, 18, 19, 20],\n",
       "        [21, 22, 23, 24, 25]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "611e2ccf-5fc3-4804-aec6-4cd4e2e0b823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2065, -0.4713,  0.9528, -1.1330])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(teacher_output,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f423a49-15b8-441f-9dff-24091ca83997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.9272,  2.7210, -1.5340,  0.2952])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(teacher_output,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6942026b-cc1b-46c5-8f5e-1681ae921203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*16*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1d64414-162d-47ab-a453-8ac247b726c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884736"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96*96*96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8e4fdb7-4e9c-4353-b682-358c5bcd0ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(96*96*96)/(16*16*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65814b10-820c-497c-bd73-074d71ec0a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6461,  0.3358,  0.5791, -3.6048],\n",
       "        [ 0.5991,  0.2356,  0.2242,  1.3083],\n",
       "        [ 0.2423,  0.3662,  0.1327,  2.1231],\n",
       "        [ 0.8047,  0.0623,  0.0640,  1.1734]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "316a94f9-d8a1-489c-964c-c06fed62dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5424, -1.0715,  0.0973, -0.6550],\n",
      "        [-0.5035, -1.8907,  1.4194,  0.6357],\n",
      "        [ 1.6272, -0.4093,  0.3786, -0.0419],\n",
      "        [ 0.1899,  1.7773,  1.0848, -0.2223]])\n",
      "tensor([[-0.1758,  0.1680,  0.0082,  0.5776],\n",
      "        [-0.1632,  0.2965,  0.1191, -0.5606],\n",
      "        [ 0.5275,  0.0642,  0.0318,  0.0370],\n",
      "        [ 0.0616, -0.2787,  0.0910,  0.1961]])\n",
      "tensor([0.2500, 0.2500, 0.2500, 0.2500])\n"
     ]
    }
   ],
   "source": [
    "Q = torch.randn(4, 4)\n",
    "print(Q)\n",
    "Q = Q/torch.sum(Q, dim=0, keepdim=True)\n",
    "Q /= 4\n",
    "print(Q)\n",
    "print(torch.sum(Q,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f109258-b5d2-4f5a-aab7-35bc46c229dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1758,  0.1680,  0.0082,  0.5776],\n",
      "        [-0.1632,  0.2965,  0.1191, -0.5606],\n",
      "        [ 0.5275,  0.0642,  0.0318,  0.0370],\n",
      "        [ 0.0616, -0.2787,  0.0910,  0.1961]])\n",
      "tensor([[-0.0761,  0.0727,  0.0035,  0.2498],\n",
      "        [ 0.1324, -0.2404, -0.0966,  0.4546],\n",
      "        [ 0.1997,  0.0243,  0.0120,  0.0140],\n",
      "        [ 0.2201, -0.9966,  0.3254,  0.7011]])\n",
      "tensor([0.2500, 0.2500, 0.2500, 0.2500])\n"
     ]
    }
   ],
   "source": [
    "print(Q)\n",
    "Q = Q/torch.sum(Q, dim=1, keepdim=True)\n",
    "Q /= 4\n",
    "print(Q)\n",
    "print(torch.sum(Q,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5152cc05-9e74-43a4-a2c6-76ba5646a68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3363, -0.9429, -0.9437, -0.2731],\n",
      "        [-0.9939, -0.4279, -0.3170,  0.0103],\n",
      "        [-2.6770,  0.6739,  0.7381, -0.6415],\n",
      "        [-0.2887, -0.1877,  0.7344, -0.2026]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-11.7797,  -2.5179,  -2.5611,  15.2144])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "s = torch.randn(4, 4)\n",
    "t = torch.randn(4, 4)\n",
    "print(s)\n",
    "torch.sum(t * F.log_softmax(s / 0.1, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f360e79-d4bd-4741-a110-edf24967c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = F.log_softmax(s / 0.1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ea9042e-c887-42d5-84e9-c247e9202c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-15.7476, -17.8935, -50.2803, -28.8236])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(vv, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e8568-4ffc-4739-98b3-9d0f31c33838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
